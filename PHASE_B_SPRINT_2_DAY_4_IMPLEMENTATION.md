# ðŸ¤– Phase B Sprint 2 Day 4 - Compliance Automation & Advanced Features

**Phase**: B - Advanced Reporting & Analytics  
**Sprint**: 2 - Report Generation & Compliance  
**Day**: 4 - Compliance Automation & Advanced Features  
**Focus**: Automated compliance checks, regulatory templates, data integrity reports, and real-time monitoring

---

## ðŸŽ¯ **Day 4 Objectives**

### **Primary Goals:**
- [ ] Build automated compliance checking system with real-time scoring
- [ ] Create pre-built regulatory report templates for audits
- [ ] Implement data integrity reporting with gap identification
- [ ] Develop real-time compliance dashboard with monitoring alerts
- [ ] Create compliance automation workflows and triggers
- [ ] Build advanced compliance analytics and predictive capabilities

### **Deliverables:**
- Automated compliance scoring engine with real-time updates
- Pre-built regulatory audit templates (FDA, ISO, CFR Part 11)
- Data integrity analysis and gap identification reports
- Real-time compliance monitoring dashboard with alerts
- Automated compliance workflow engine
- Predictive compliance analytics and forecasting

---

## ðŸ—ï¸ **Building on Days 1-3 Foundation**

### **Existing Infrastructure:**
- âœ… **Template Processing Pipeline** (Day 2): Multi-source data aggregation and chart generation
- âœ… **Regulatory Framework** (Day 3): CFR Part 11, ISO 13485, FDA reporting services
- âœ… **Advanced Dashboard** (Day 3): Real-time regulatory compliance monitoring
- âœ… **Compliance Validation** (Day 3): Comprehensive validation and data integrity checking
- âœ… **Report Generation** (Day 1): Professional PDF and Excel generation

### **Day 4 Automation Enhancements:**
- ðŸ”œ **Automated Compliance Engine**: Real-time compliance monitoring and scoring
- ðŸ”œ **Regulatory Template Library**: Pre-built audit-ready report templates
- ðŸ”œ **Data Integrity Automation**: Automated gap detection and remediation workflows
- ðŸ”œ **Compliance Workflow Engine**: Event-driven compliance automation
- ðŸ”œ **Predictive Analytics**: AI-powered compliance forecasting and risk assessment
- ðŸ”œ **Advanced Monitoring**: Real-time alerting and automated remediation

---

## ðŸ¤– **Automated Compliance Checking System**

### **Real-time Compliance Scoring Engine**

#### **Automated Compliance Service**
```python
# backend/app/services/compliance/automated_compliance_service.py
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from sqlalchemy.orm import Session
from sqlalchemy import text
import asyncio
import json
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class ComplianceStatus(Enum):
    """Compliance status levels"""
    COMPLIANT = "compliant"
    WARNING = "warning"
    NON_COMPLIANT = "non_compliant"
    CRITICAL = "critical"
    UNKNOWN = "unknown"

class ComplianceCheckType(Enum):
    """Types of compliance checks"""
    REAL_TIME = "real_time"
    SCHEDULED = "scheduled"
    EVENT_DRIVEN = "event_driven"
    ON_DEMAND = "on_demand"

@dataclass
class ComplianceRule:
    """Individual compliance rule definition"""
    rule_id: str
    rule_name: str
    description: str
    regulation: str  # CFR_PART_11, ISO_13485, FDA_QSR, etc.
    check_function: str
    parameters: Dict[str, Any]
    severity: str  # critical, high, medium, low
    frequency: str  # real_time, hourly, daily, weekly
    enabled: bool = True
    last_check: Optional[datetime] = None
    last_result: Optional[str] = None

@dataclass
class ComplianceResult:
    """Result of a compliance check"""
    rule_id: str
    check_timestamp: datetime
    status: ComplianceStatus
    score: float  # 0-100
    details: Dict[str, Any]
    violations: List[Dict[str, Any]]
    recommendations: List[str]
    remediation_actions: List[Dict[str, Any]]
    next_check_due: datetime

@dataclass
class ComplianceScore:
    """Overall compliance scoring"""
    overall_score: float
    regulation_scores: Dict[str, float]
    module_scores: Dict[str, float]
    trend_direction: str  # improving, declining, stable
    last_updated: datetime
    score_history: List[Dict[str, Any]]

class AutomatedComplianceService:
    """
    Automated Compliance Checking Service
    Real-time compliance monitoring, scoring, and alerting
    """
    
    def __init__(self, 
                 db: Session,
                 cfr_service=None,
                 iso_service=None,
                 fda_service=None,
                 validation_service=None):
        self.db = db
        self.cfr_service = cfr_service
        self.iso_service = iso_service
        self.fda_service = fda_service
        self.validation_service = validation_service
        
        # Load compliance rules
        self.compliance_rules = self._load_compliance_rules()
        
        # Compliance check registry
        self.check_functions = self._register_check_functions()
        
        # Scoring weights
        self.scoring_weights = self._load_scoring_weights()
        
    async def run_automated_compliance_check(self, 
                                           check_type: ComplianceCheckType = ComplianceCheckType.SCHEDULED,
                                           rule_ids: Optional[List[str]] = None) -> Dict[str, ComplianceResult]:
        """
        Run automated compliance checks
        
        Args:
            check_type: Type of compliance check to run
            rule_ids: Specific rules to check (None for all applicable rules)
            
        Returns:
            Dictionary of compliance results by rule ID
        """
        
        logger.info(f"Starting automated compliance check: {check_type.value}")
        
        # Determine which rules to check
        rules_to_check = self._get_applicable_rules(check_type, rule_ids)
        
        # Run compliance checks concurrently
        check_tasks = []
        for rule in rules_to_check:
            if rule.enabled:
                task = self._execute_compliance_rule(rule)
                check_tasks.append((rule.rule_id, task))
        
        # Collect results
        compliance_results = {}
        
        for rule_id, task in check_tasks:
            try:
                result = await task
                compliance_results[rule_id] = result
                
                # Update rule's last check
                rule = next(r for r in self.compliance_rules if r.rule_id == rule_id)
                rule.last_check = datetime.now()
                rule.last_result = result.status.value
                
            except Exception as e:
                logger.error(f"Compliance check failed for rule {rule_id}: {str(e)}")
                
                # Create error result
                compliance_results[rule_id] = ComplianceResult(
                    rule_id=rule_id,
                    check_timestamp=datetime.now(),
                    status=ComplianceStatus.UNKNOWN,
                    score=0.0,
                    details={'error': str(e)},
                    violations=[],
                    recommendations=[f"Fix compliance check error: {str(e)}"],
                    remediation_actions=[],
                    next_check_due=datetime.now() + timedelta(hours=1)
                )
        
        # Calculate overall compliance score
        overall_score = await self._calculate_compliance_score(compliance_results)
        
        # Store results
        await self._store_compliance_results(compliance_results, overall_score)
        
        # Process alerts and notifications
        await self._process_compliance_alerts(compliance_results, overall_score)
        
        logger.info(f"Automated compliance check completed: {len(compliance_results)} rules checked")
        
        return compliance_results
    
    async def _execute_compliance_rule(self, rule: ComplianceRule) -> ComplianceResult:
        """Execute a single compliance rule"""
        
        check_function = self.check_functions.get(rule.check_function)
        if not check_function:
            raise ValueError(f"Unknown check function: {rule.check_function}")
        
        # Execute the compliance check
        result = await check_function(rule.parameters)
        
        # Calculate score based on result
        score = self._calculate_rule_score(result, rule)
        
        # Determine status
        status = self._determine_compliance_status(score, rule.severity)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(result, rule)
        
        # Generate remediation actions
        remediation_actions = self._generate_remediation_actions(result, rule)
        
        # Calculate next check time
        next_check = self._calculate_next_check_time(rule)
        
        return ComplianceResult(
            rule_id=rule.rule_id,
            check_timestamp=datetime.now(),
            status=status,
            score=score,
            details=result,
            violations=result.get('violations', []),
            recommendations=recommendations,
            remediation_actions=remediation_actions,
            next_check_due=next_check
        )
    
    def _register_check_functions(self) -> Dict[str, Callable]:
        """Register compliance check functions"""
        
        return {
            'cfr_part11_electronic_records': self._check_cfr_electronic_records,
            'cfr_part11_signatures': self._check_cfr_signatures,
            'cfr_part11_audit_trails': self._check_cfr_audit_trails,
            'iso13485_document_control': self._check_iso_document_control,
            'iso13485_training_effectiveness': self._check_iso_training,
            'iso13485_nonconformity_management': self._check_iso_nonconformity,
            'fda_adverse_event_reporting': self._check_fda_adverse_events,
            'fda_device_tracking': self._check_fda_device_tracking,
            'data_integrity_orphaned_records': self._check_data_integrity_orphaned,
            'data_integrity_consistency': self._check_data_integrity_consistency,
            'audit_trail_completeness': self._check_audit_completeness,
            'security_access_controls': self._check_security_access,
            'quality_event_resolution': self._check_quality_resolution,
            'training_compliance': self._check_training_compliance,
            'document_approval_workflow': self._check_document_workflow,
            'capa_effectiveness': self._check_capa_effectiveness
        }
    
    async def _check_cfr_electronic_records(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Check CFR Part 11 electronic records compliance"""
        
        # Query electronic records compliance
        records_query = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(CASE WHEN checksum IS NOT NULL THEN 1 END) as checksummed_records,
                COUNT(CASE WHEN created_by IS NOT NULL THEN 1 END) as attributed_records,
                COUNT(CASE WHEN created_at IS NOT NULL THEN 1 END) as timestamped_records,
                COUNT(CASE WHEN digital_signature IS NOT NULL THEN 1 END) as signed_records
            FROM (
                SELECT id, checksum, created_by, created_at, 
                       COALESCE(digital_signature, signature_data) as digital_signature 
                FROM documents WHERE is_deleted = false
                UNION ALL
                SELECT id, checksum, created_by, created_at, 
                       signature_data as digital_signature 
                FROM quality_events WHERE is_deleted = false
                UNION ALL
                SELECT id, checksum, created_by, created_at, 
                       NULL as digital_signature 
                FROM training_programs WHERE is_deleted = false
            ) combined_records
        """
        
        result = self.db.execute(text(records_query))
        data = dict(zip(result.keys(), result.fetchone() or [0]*5))
        
        total_records = data.get('total_records', 0)
        violations = []
        
        if total_records == 0:
            return {
                'compliance_percentage': 100,
                'violations': [],
                'details': 'No electronic records found'
            }
        
        # Calculate compliance percentages
        checksum_coverage = (data.get('checksummed_records', 0) / total_records) * 100
        attribution_coverage = (data.get('attributed_records', 0) / total_records) * 100
        timestamp_coverage = (data.get('timestamped_records', 0) / total_records) * 100
        
        # Check for violations
        if checksum_coverage < 95:
            violations.append({
                'type': 'insufficient_integrity_protection',
                'description': f'Only {checksum_coverage:.1f}% of records have integrity protection',
                'severity': 'high',
                'affected_records': total_records - data.get('checksummed_records', 0)
            })
        
        if attribution_coverage < 98:
            violations.append({
                'type': 'insufficient_attribution',
                'description': f'Only {attribution_coverage:.1f}% of records have proper attribution',
                'severity': 'critical',
                'affected_records': total_records - data.get('attributed_records', 0)
            })
        
        if timestamp_coverage < 99:
            violations.append({
                'type': 'insufficient_timestamps',
                'description': f'Only {timestamp_coverage:.1f}% of records have timestamps',
                'severity': 'medium',
                'affected_records': total_records - data.get('timestamped_records', 0)
            })
        
        # Calculate overall compliance
        compliance_percentage = (checksum_coverage + attribution_coverage + timestamp_coverage) / 3
        
        return {
            'compliance_percentage': round(compliance_percentage, 2),
            'violations': violations,
            'details': {
                'total_records': total_records,
                'checksum_coverage': round(checksum_coverage, 2),
                'attribution_coverage': round(attribution_coverage, 2),
                'timestamp_coverage': round(timestamp_coverage, 2),
                'signed_records': data.get('signed_records', 0)
            }
        }
    
    async def _check_training_compliance(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Check training compliance across the organization"""
        
        # Get training compliance metrics
        training_query = """
            SELECT 
                COUNT(*) as total_assignments,
                COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_assignments,
                COUNT(CASE WHEN due_date < NOW() AND status != 'completed' THEN 1 END) as overdue_assignments,
                COUNT(CASE WHEN due_date <= NOW() + INTERVAL '7 days' AND status != 'completed' THEN 1 END) as due_soon_assignments,
                AVG(CASE WHEN status = 'completed' AND completed_at IS NOT NULL AND due_date IS NOT NULL 
                         THEN EXTRACT(EPOCH FROM (completed_at - due_date))/86400 
                    END) as avg_completion_delay_days
            FROM training_assignments 
            WHERE is_deleted = false
            AND created_at >= NOW() - INTERVAL '90 days'
        """
        
        result = self.db.execute(text(training_query))
        data = dict(zip(result.keys(), result.fetchone() or [0]*5))
        
        total_assignments = data.get('total_assignments', 0)
        violations = []
        
        if total_assignments == 0:
            return {
                'compliance_percentage': 100,
                'violations': [],
                'details': 'No training assignments found'
            }
        
        # Calculate metrics
        completion_rate = (data.get('completed_assignments', 0) / total_assignments) * 100
        overdue_rate = (data.get('overdue_assignments', 0) / total_assignments) * 100
        avg_delay = data.get('avg_completion_delay_days', 0) or 0
        
        # Check for violations
        if completion_rate < 90:
            violations.append({
                'type': 'low_completion_rate',
                'description': f'Training completion rate is {completion_rate:.1f}% (target: 90%)',
                'severity': 'high',
                'affected_assignments': total_assignments - data.get('completed_assignments', 0)
            })
        
        if overdue_rate > 5:
            violations.append({
                'type': 'excessive_overdue_training',
                'description': f'{overdue_rate:.1f}% of training assignments are overdue',
                'severity': 'critical',
                'affected_assignments': data.get('overdue_assignments', 0)
            })
        
        if avg_delay > 5:
            violations.append({
                'type': 'delayed_completion',
                'description': f'Average completion delay is {avg_delay:.1f} days',
                'severity': 'medium',
                'impact': 'Training effectiveness may be compromised'
            })
        
        # Calculate compliance score
        compliance_score = max(0, 100 - (overdue_rate * 2) - max(0, (10 - (completion_rate - 90))))
        
        return {
            'compliance_percentage': round(compliance_score, 2),
            'violations': violations,
            'details': {
                'total_assignments': total_assignments,
                'completion_rate': round(completion_rate, 2),
                'overdue_rate': round(overdue_rate, 2),
                'due_soon': data.get('due_soon_assignments', 0),
                'avg_completion_delay_days': round(avg_delay, 1)
            }
        }
    
    async def _check_quality_resolution(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Check quality event resolution compliance"""
        
        # Quality event resolution metrics
        quality_query = """
            SELECT 
                COUNT(*) as total_events,
                COUNT(CASE WHEN status IN ('closed', 'resolved') THEN 1 END) as resolved_events,
                COUNT(CASE WHEN priority = 'high' AND status NOT IN ('closed', 'resolved') THEN 1 END) as open_high_priority,
                COUNT(CASE WHEN created_at <= NOW() - INTERVAL '30 days' AND status NOT IN ('closed', 'resolved') THEN 1 END) as overdue_events,
                AVG(CASE WHEN status IN ('closed', 'resolved') AND resolved_at IS NOT NULL 
                         THEN EXTRACT(EPOCH FROM (resolved_at - created_at))/86400 
                    END) as avg_resolution_days
            FROM quality_events 
            WHERE is_deleted = false
            AND created_at >= NOW() - INTERVAL '90 days'
        """
        
        result = self.db.execute(text(quality_query))
        data = dict(zip(result.keys(), result.fetchone() or [0]*5))
        
        total_events = data.get('total_events', 0)
        violations = []
        
        if total_events == 0:
            return {
                'compliance_percentage': 100,
                'violations': [],
                'details': 'No quality events found'
            }
        
        # Calculate metrics
        resolution_rate = (data.get('resolved_events', 0) / total_events) * 100
        overdue_rate = (data.get('overdue_events', 0) / total_events) * 100
        avg_resolution_time = data.get('avg_resolution_days', 0) or 0
        open_high_priority = data.get('open_high_priority', 0)
        
        # Check for violations
        if resolution_rate < 85:
            violations.append({
                'type': 'low_resolution_rate',
                'description': f'Quality event resolution rate is {resolution_rate:.1f}% (target: 85%)',
                'severity': 'high',
                'affected_events': total_events - data.get('resolved_events', 0)
            })
        
        if open_high_priority > 0:
            violations.append({
                'type': 'open_high_priority_events',
                'description': f'{open_high_priority} high priority events remain open',
                'severity': 'critical',
                'affected_events': open_high_priority
            })
        
        if overdue_rate > 10:
            violations.append({
                'type': 'excessive_overdue_events',
                'description': f'{overdue_rate:.1f}% of events are overdue for resolution',
                'severity': 'high',
                'affected_events': data.get('overdue_events', 0)
            })
        
        if avg_resolution_time > 14:
            violations.append({
                'type': 'slow_resolution',
                'description': f'Average resolution time is {avg_resolution_time:.1f} days (target: 14 days)',
                'severity': 'medium',
                'impact': 'Quality system effectiveness may be compromised'
            })
        
        # Calculate compliance score
        compliance_score = max(0, 100 - (overdue_rate * 1.5) - (open_high_priority * 5) - max(0, (avg_resolution_time - 14)))
        
        return {
            'compliance_percentage': round(compliance_score, 2),
            'violations': violations,
            'details': {
                'total_events': total_events,
                'resolution_rate': round(resolution_rate, 2),
                'overdue_rate': round(overdue_rate, 2),
                'open_high_priority': open_high_priority,
                'avg_resolution_days': round(avg_resolution_time, 1)
            }
        }
```

This is the beginning of our comprehensive Compliance Automation system. Should I continue with:

1. **Complete the Automated Compliance Service** with all check functions
2. **Build the Regulatory Template Library** with pre-built audit templates
3. **Create the Data Integrity Automation** system
4. **Develop the Compliance Workflow Engine**

What would you like me to focus on next for Day 4?